{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"/home/taha/Documents/ML/iris.txt\"\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "# Column labels.\n",
    "headers = [\"sepal length\", \"sepal width\", \"petal length\", \"petal width\" , \"label\"]\n",
    "\n",
    "df.columns = headers\n",
    "\n",
    "# Converting labels to numeric.\n",
    "label_map = {\"Iris-setosa\":0, \"Iris-versicolor\":1, \"Iris-virginica\":2}\n",
    "df['label'] = df['label'].map(label_map)\n",
    "\n",
    "train = df.sample(frac=0.8,random_state=200)\n",
    "test = df.drop(train.index)\n",
    "\n",
    "training_dataset = train.values\n",
    "testing_dataset = test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of X is: (4, 119)\n",
      "The shape of Y is: (3, 119)\n",
      "I have m = 119 training examples!\n"
     ]
    }
   ],
   "source": [
    "classes = 3\n",
    "X = training_dataset[:, :-1].T\n",
    "Y_orig = (training_dataset[:, -1].reshape(1,X.shape[1])).astype(int)\n",
    "X_test = testing_dataset[:, :-1].T\n",
    "Y_test_orig = (testing_dataset[:, -1].reshape(1,X_test.shape[1])).astype(int)\n",
    "\n",
    "m = X.shape[1]\n",
    "\n",
    "#Modifying Y for multi class Classification\n",
    "Y = np.zeros((m, classes))\n",
    "Y[np.arange(m), Y_orig] = 1\n",
    "Y = Y.T\n",
    "\n",
    "Y_test = np.zeros((X_test.shape[1], classes))\n",
    "Y_test[np.arange(X_test.shape[1]), Y_test_orig] = 1\n",
    "Y_test = Y_test.T\n",
    "\n",
    "\n",
    "print ('The shape of X is: ' + str(X.shape))\n",
    "print ('The shape of Y is: ' + str(Y.shape))\n",
    "print ('I have m = %d training examples!' % (m))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def layer_sizes(X, Y):\n",
    "    n_x = X.shape[0] # size of input layer\n",
    "    n_y = Y.shape[0] # size of output layer\n",
    "            \n",
    "    return (n_x, n_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_parameters(n_x,n_y):\n",
    "    \n",
    "    W = np.random.randn(n_y,n_x) * 0.01\n",
    "    b = np.zeros((n_y,1)) \n",
    "    \n",
    "    parameters = {\"W\": W,\n",
    "                  \"b\": b}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(X):\n",
    "    \n",
    "    return 1.0 / (1.0 + np.exp(-1.0 * X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    exps = np.exp(X)\n",
    "    return exps / exps.sum(axis=0, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    W = parameters['W']\n",
    "    b = parameters['b']\n",
    "    \n",
    "    Z = np.dot(W,X) + b\n",
    "    A = softmax(Z)\n",
    "    \n",
    "    cache = {\"Z\": Z,\n",
    "             \"A\": A}\n",
    "    \n",
    "    return A, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost(A, Y, parameters):\n",
    "    \n",
    "    m = Y.shape[1]\n",
    "    \n",
    "    logprobs = np.multiply(np.log(A),-Y)\n",
    "    #column wise\n",
    "    cost = np.sum(logprobs,axis=0,keepdims=True)\n",
    "    #over all training examples\n",
    "    cost = np.sum(cost)/m\n",
    "    cost = np.squeeze(cost)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    W = parameters['W']\n",
    "    \n",
    "    A = cache['A']\n",
    "    \n",
    "    dZ = A - Y\n",
    "    dW = (1/m) * np.dot(dZ,X.T)\n",
    "    db = (1/m) * np.sum(dZ,axis=1,keepdims=True)\n",
    "    \n",
    "    grads = {\"dW\": dW,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_parameters(parameters, grads, learning_rate = 0.5):\n",
    "    \n",
    "    W = parameters['W']\n",
    "    b = parameters['b']\n",
    "    \n",
    "    dW = grads['dW']\n",
    "    db = grads['db']\n",
    "   \n",
    "    # Update rule for each parameter\n",
    "    W = W - learning_rate * dW\n",
    "    b = b - learning_rate * db\n",
    "    \n",
    "    parameters = {\"W\": W,\n",
    "                  \"b\": b}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model(X, Y, num_iterations = 10000, print_cost=False):\n",
    "    \n",
    "    n_x = layer_sizes(X, Y)[0]\n",
    "    n_y = layer_sizes(X, Y)[1]\n",
    "    \n",
    "    parameters = initialize_parameters(n_x,n_y)\n",
    "    W = parameters['W']\n",
    "    b = parameters['b']\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "        \n",
    "        # Forward propagation\n",
    "        A, cache = forward_propagation(X, parameters)\n",
    "   \n",
    "        # Cost function\n",
    "        cost = compute_cost(A, Y, parameters)\n",
    " \n",
    "        # Backpropagation\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    " \n",
    "        # Gradient descent parameter update\n",
    "        parameters = update_parameters(parameters, grads)\n",
    "        \n",
    "        # Print the cost every 1000 iterations\n",
    "        if print_cost and i % 1000 == 0:\n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    \n",
    "    A, cache = forward_propagation(X, parameters)\n",
    "    predictions = (A == A.max(axis=0)[None,:]).astype(int)\n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 1.102285\n",
      "Cost after iteration 1000: 0.074236\n",
      "Cost after iteration 2000: 0.068664\n",
      "Cost after iteration 3000: 0.065081\n",
      "Cost after iteration 4000: 0.062460\n",
      "Cost after iteration 5000: 0.060447\n",
      "Cost after iteration 6000: 0.058845\n",
      "Cost after iteration 7000: 0.057533\n",
      "Cost after iteration 8000: 0.056432\n",
      "Cost after iteration 9000: 0.055492\n"
     ]
    }
   ],
   "source": [
    "parameters = nn_model(X, Y,num_iterations = 10000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 100%\n"
     ]
    }
   ],
   "source": [
    "# Print accuracy\n",
    "predictions = predict(parameters, X_test)\n",
    "correct_classified = np.sum(np.multiply(Y_test,predictions),axis=0)\n",
    "\n",
    "print ('Accuracy: %d' % float( np.sum(correct_classified)/float(Y_test.shape[1])*100) + '%')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
